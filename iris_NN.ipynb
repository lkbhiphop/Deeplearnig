{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_train = np.loadtxt(\"iris_training.csv\",delimiter=\",\",dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_train[:100,[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_label = iris_train[:,[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_label = sess.run(tf.one_hot(y_label,depth = 3))\n",
    "y_label = sess.run(tf.reshape(y_label,[-1,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = iris_train[:,:-1]\n",
    "y_train= y_label[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = tf.placeholder(tf.float32, shape = [None, 4])\n",
    "# Y = tf.placeholder(tf.int32, shape = [None, 1])\n",
    "# #one hot incoding\n",
    "# Y_one_hot = tf.one_hot(Y, 3)\n",
    "# Y_one_hot = tf.reshape(Y_one_hot, [-1, 3])\n",
    "\n",
    "# W1 = tf.Variable(tf.random_normal([4,10]))\n",
    "# b1 = tf.Variable(tf.random_normal([10]))\n",
    "# layer1 = tf.nn.relu(tf.matmul(X,W1)+b1)\n",
    "\n",
    "# W2 = tf.Variable(tf.random_normal([10,10]))\n",
    "# b2 = tf.Variable(tf.random_normal([10]))\n",
    "# layer2 = tf.nn.relu(tf.matmul(layer1,W2)+b2)\n",
    "\n",
    "# W3 = tf.Variable(tf.random_normal([10,3]))\n",
    "# b3 = tf.Variable(tf.random_normal([3]))\n",
    "# logits = tf.matmul(layer2,W3)+b3\n",
    "# hypothesis = tf.nn.softmax(logits)\n",
    "\n",
    "# #cost = -tf.reduce_mean(tf.reduce_sum(Y * tf.log(hypothesis), axis=1))\n",
    "# cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y_one_hot))\n",
    "# train = tf.train.AdamOptimizer(learning_rate=0.1).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-13-3302bebee084>:28: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32,shape = [None,4])\n",
    "Y = tf.placeholder(tf.float32, shape = [None,3])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "#one hot incoding\n",
    "# Y_one_hot = tf.one_hot(Y, 3)\n",
    "# Y_one_hot = tf.reshape(Y_one_hot, [-1, 3])\n",
    "\n",
    "W1 = tf.get_variable(\"W1\",shape = [4,10], initializer= tf.contrib.layers.xavier_initializer())\n",
    "# W1 = tf.Variable(tf.random_normal([4,10]))\n",
    "b1 = tf.Variable(tf.random_normal([10]))\n",
    "layer1 = tf.nn.relu(tf.matmul(X,W1)+b1)\n",
    "layer1 = tf.nn.dropout(layer1,keep_prob = keep_prob)\n",
    "\n",
    "W2 = tf.get_variable(\"W2\",shape = [10,10], initializer= tf.contrib.layers.xavier_initializer())\n",
    "# W2 = tf.Variable(tf.random_normal([10,10]))\n",
    "b2 = tf.Variable(tf.random_normal([10]))\n",
    "layer2 = tf.nn.relu(tf.matmul(layer1,W2)+b2)\n",
    "layer2 = tf.nn.dropout(layer2,keep_prob = keep_prob)\n",
    "\n",
    "W3 = tf.get_variable(\"W3\",shape = [10,3], initializer= tf.contrib.layers.xavier_initializer())\n",
    "# W3 = tf.Variable(tf.random_normal([10,3]))\n",
    "b3 = tf.Variable(tf.random_normal([3]))\n",
    "logits = tf.matmul(layer2,W3)+b3\n",
    "\n",
    "hypothesis = tf.nn.softmax(logits)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits,labels=Y))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 cost: 2.2390883\n",
      "step: 100 cost: 0.88660365\n",
      "step: 200 cost: 0.78604126\n",
      "step: 300 cost: 0.6784247\n",
      "step: 400 cost: 0.6809514\n",
      "step: 500 cost: 0.7118364\n",
      "step: 600 cost: 0.7319189\n",
      "step: 700 cost: 0.5506418\n",
      "step: 800 cost: 0.7154134\n",
      "step: 900 cost: 0.6561648\n",
      "step: 1000 cost: 0.63815755\n",
      "step: 1100 cost: 0.68902105\n",
      "step: 1200 cost: 0.68851763\n",
      "step: 1300 cost: 0.69224334\n",
      "step: 1400 cost: 0.734629\n",
      "step: 1500 cost: 0.6749686\n",
      "step: 1600 cost: 0.58853364\n",
      "step: 1700 cost: 0.63727343\n",
      "step: 1800 cost: 0.5553939\n",
      "step: 1900 cost: 0.6159365\n",
      "step: 2000 cost: 0.7394012\n",
      "step: 2100 cost: 0.6093161\n",
      "step: 2200 cost: 0.592156\n",
      "step: 2300 cost: 0.57819664\n",
      "step: 2400 cost: 0.6093567\n",
      "step: 2500 cost: 0.5343767\n",
      "step: 2600 cost: 0.57925755\n",
      "step: 2700 cost: 0.57435775\n",
      "step: 2800 cost: 0.55872166\n",
      "step: 2900 cost: 0.614685\n",
      "step: 3000 cost: 0.5831659\n",
      "step: 3100 cost: 0.59088874\n",
      "step: 3200 cost: 0.57686055\n",
      "step: 3300 cost: 0.51400065\n",
      "step: 3400 cost: 0.6107188\n",
      "step: 3500 cost: 0.4486452\n",
      "step: 3600 cost: 0.519517\n",
      "step: 3700 cost: 0.5632143\n",
      "step: 3800 cost: 0.46345598\n",
      "step: 3900 cost: 0.6146869\n",
      "step: 4000 cost: 0.5569439\n",
      "step: 4100 cost: 0.5619465\n",
      "step: 4200 cost: 0.61970544\n",
      "step: 4300 cost: 0.5727188\n",
      "step: 4400 cost: 0.6264684\n",
      "step: 4500 cost: 0.5155844\n",
      "step: 4600 cost: 0.6495175\n",
      "step: 4700 cost: 0.54792815\n",
      "step: 4800 cost: 0.6350845\n",
      "step: 4900 cost: 0.6718212\n",
      "step: 5000 cost: 0.5645497\n",
      "step: 5100 cost: 0.48442498\n",
      "step: 5200 cost: 0.57028586\n",
      "step: 5300 cost: 0.57285714\n",
      "step: 5400 cost: 0.60622394\n",
      "step: 5500 cost: 0.55967253\n",
      "step: 5600 cost: 0.5571673\n",
      "step: 5700 cost: 0.5185996\n",
      "step: 5800 cost: 0.59639776\n",
      "step: 5900 cost: 0.6345426\n",
      "step: 6000 cost: 0.6125772\n",
      "step: 6100 cost: 0.5866052\n",
      "step: 6200 cost: 0.5316037\n",
      "step: 6300 cost: 0.44185054\n",
      "step: 6400 cost: 0.51696485\n",
      "step: 6500 cost: 0.47986683\n",
      "step: 6600 cost: 0.50542206\n",
      "step: 6700 cost: 0.593383\n",
      "step: 6800 cost: 0.5190755\n",
      "step: 6900 cost: 0.7017423\n",
      "step: 7000 cost: 0.555061\n",
      "step: 7100 cost: 0.5603884\n",
      "step: 7200 cost: 0.5876699\n",
      "step: 7300 cost: 0.53574604\n",
      "step: 7400 cost: 0.51908594\n",
      "step: 7500 cost: 0.697864\n",
      "step: 7600 cost: 0.51147497\n",
      "step: 7700 cost: 0.470006\n",
      "step: 7800 cost: 0.56570727\n",
      "step: 7900 cost: 0.64779836\n",
      "step: 8000 cost: 0.52925646\n",
      "step: 8100 cost: 0.5088475\n",
      "step: 8200 cost: 0.50556105\n",
      "step: 8300 cost: 0.5692044\n",
      "step: 8400 cost: 0.64079016\n",
      "step: 8500 cost: 0.6207836\n",
      "step: 8600 cost: 0.5476893\n",
      "step: 8700 cost: 0.61144084\n",
      "step: 8800 cost: 0.58761317\n",
      "step: 8900 cost: 0.51521933\n",
      "step: 9000 cost: 0.5510863\n",
      "step: 9100 cost: 0.5991828\n",
      "step: 9200 cost: 0.504338\n",
      "step: 9300 cost: 0.5113808\n",
      "step: 9400 cost: 0.55168915\n",
      "step: 9500 cost: 0.5374866\n",
      "step: 9600 cost: 0.529043\n",
      "step: 9700 cost: 0.50158364\n",
      "step: 9800 cost: 0.64754623\n",
      "step: 9900 cost: 0.5449337\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(10000):\n",
    "    c_v, _ = sess.run([cost,train], feed_dict={X:x_train,Y:y_train,keep_prob : 0.5})\n",
    "    if step % 100 == 0:\n",
    "        print(\"step:\",step,\"cost:\",c_v )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_correct = tf.equal(tf.argmax(hypothesis,1),tf.argmax(Y,1))\n",
    "# hypothesis(예측값) 중 가장 큰 값의 index를 뽑아내는 것\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_test = np.loadtxt(\"iris_test.csv\",delimiter=\",\",dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_label = iris_test[:,[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_label = sess.run(tf.one_hot(y_test_label,depth = 3))\n",
    "y_test_label = sess.run(tf.reshape(y_test_label, shape=[-1,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = iris_test[:,:-1]\n",
    "y_test= y_test_label[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96666664"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(accuracy, feed_dict={X:x_test,Y:y_test,keep_prob :1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최저점을 찾는 것은 조금 어렵다. \n",
    "# 코스트가 올라가는 시점에서 멈추면된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
