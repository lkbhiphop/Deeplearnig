{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1단계 - 그래프 build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [1,2,3]\n",
    "y_train = [11,20,29]\n",
    "#\n",
    "#Variable은 항상 초기화를 해줘야한다. \n",
    "W = tf.Variable(tf.random_normal([1]),name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
    "# 내가 찾고자 하는 선, 그래프\n",
    "hypothesis = x_train * W + b\n",
    "cost  = tf.reduce_mean(tf.square(hypothesis-y_train))\n",
    "# 패키지를 이용한 경사하강법\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.Tensor"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2단계 - session으로 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 Cost: 380.4652 W: [0.1826517] b: [1.5064107]\n",
      "Step: 100 Cost: 0.7131366 W: [8.019136] b: [4.229573]\n",
      "Step: 200 Cost: 0.44067487 W: [8.228998] b: [3.7526677]\n",
      "Step: 300 Cost: 0.2723103 W: [8.393922] b: [3.3777573]\n",
      "Step: 400 Cost: 0.16827147 W: [8.523568] b: [3.0830426]\n",
      "Step: 500 Cost: 0.103981495 W: [8.625481] b: [2.85137]\n",
      "Step: 600 Cost: 0.06425408 W: [8.705594] b: [2.6692545]\n",
      "Step: 700 Cost: 0.039705027 W: [8.768571] b: [2.5260935]\n",
      "Step: 800 Cost: 0.024535254 W: [8.818074] b: [2.4135582]\n",
      "Step: 900 Cost: 0.015161191 W: [8.856991] b: [2.3250928]\n",
      "Step: 1000 Cost: 0.009368648 W: [8.887582] b: [2.255552]\n",
      "Step: 1100 Cost: 0.0057893093 W: [8.911629] b: [2.2008882]\n",
      "Step: 1200 Cost: 0.0035774736 W: [8.930532] b: [2.157917]\n",
      "Step: 1300 Cost: 0.0022106704 W: [8.945392] b: [2.1241374]\n",
      "Step: 1400 Cost: 0.0013660704 W: [8.957073] b: [2.0975833]\n",
      "Step: 1500 Cost: 0.0008441755 W: [8.966254] b: [2.07671]\n",
      "Step: 1600 Cost: 0.0005216678 W: [8.973473] b: [2.0603025]\n",
      "Step: 1700 Cost: 0.00032237513 W: [8.979147] b: [2.047404]\n",
      "Step: 1800 Cost: 0.00019921137 W: [8.983607] b: [2.037264]\n",
      "Step: 1900 Cost: 0.00012311968 W: [8.987113] b: [2.029295]\n"
     ]
    }
   ],
   "source": [
    "sess= tf.Session()\n",
    "# 그래프의 variable 초기화한다\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(2000):\n",
    "    sess.run(train)\n",
    "    if step % 100 == 0:\n",
    "        print(\"Step:\",step,\"Cost:\", sess.run(cost),\"W:\",sess.run(W),\"b:\",sess.run(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 내가 찾고자하는 선까지 만들고 이를 cost functino을 만든다. \n",
    "# 그 다음 optimizer를 만들고 이를 최소화하는 메쏘드에 cost라는 이름ㅢ cost_functino을 넣어서 그래프를 완성한다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholder를 이용한 구현\n",
    "X = tf.placeholder(tf.float32, shape = [None])\n",
    "Y = tf.placeholder(tf.float32, shape = [None])\n",
    "#\n",
    "#Variable은 항상 초기화를 해줘야한다. \n",
    "W = tf.Variable(tf.random_normal([1]),name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
    "# 내가 찾고자 하는 선, 그래프\n",
    "hypothesis = X * W + b\n",
    "# operation -  tensor\n",
    "cost  = tf.reduce_mean(tf.square(hypothesis-Y))\n",
    "# 패키지를 이용한 경사하강법 optimizer생성\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하나하나의 노드를 tensor라고 데이터일 수도 있고, 연산자일 수도 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.Operation"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 Cost: 306.22534 W: [1.8936183] b: [-0.22889817]\n",
      "Step: 100 Cost: 0.52488273 W: [8.160528] b: [1.9081876]\n",
      "Step: 200 Cost: 0.32434502 W: [8.340135] b: [1.5000256]\n",
      "Step: 300 Cost: 0.20042507 W: [8.481288] b: [1.1791549]\n",
      "Step: 400 Cost: 0.12385073 W: [8.592244] b: [0.92692393]\n",
      "Step: 500 Cost: 0.076531835 W: [8.679469] b: [0.72864705]\n",
      "Step: 600 Cost: 0.047292005 W: [8.748033] b: [0.5727815]\n",
      "Step: 700 Cost: 0.029223502 W: [8.80193] b: [0.45025846]\n",
      "Step: 800 Cost: 0.018058455 W: [8.844297] b: [0.35394567]\n",
      "Step: 900 Cost: 0.011159015 W: [8.877605] b: [0.27823275]\n",
      "Step: 1000 Cost: 0.0068956055 W: [8.903787] b: [0.2187158]\n",
      "Step: 1100 Cost: 0.00426106 W: [8.924368] b: [0.17193103]\n",
      "Step: 1200 Cost: 0.0026330687 W: [8.940546] b: [0.13515314]\n",
      "Step: 1300 Cost: 0.001627102 W: [8.953263] b: [0.1062427]\n",
      "Step: 1400 Cost: 0.0010054491 W: [8.963261] b: [0.0835165]\n",
      "Step: 1500 Cost: 0.00062131614 W: [8.971119] b: [0.0656525]\n",
      "Step: 1600 Cost: 0.000383941 W: [8.977297] b: [0.05160953]\n",
      "Step: 1700 Cost: 0.00023728386 W: [8.982152] b: [0.04057157]\n",
      "Step: 1800 Cost: 0.00014663521 W: [8.98597] b: [0.03189443]\n",
      "Step: 1900 Cost: 9.0619724e-05 W: [8.988969] b: [0.02507374]\n"
     ]
    }
   ],
   "source": [
    "sess= tf.Session()\n",
    "# 그래프의 variable 초기화한다\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(2000):\n",
    "    c, w, k, _ = sess.run([cost,W,b,train], feed_dict = {X:[1,2,3],Y:[9,18,27]})\n",
    "    if step % 100 == 0:\n",
    "        print(\"Step:\",step,\"Cost:\", c,\"W:\",w,\"b:\",k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 직접구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholder를 이용한 구현\n",
    "X = tf.placeholder(tf.float32, shape = [None])\n",
    "Y = tf.placeholder(tf.float32, shape = [None])\n",
    "#\n",
    "#Variable은 항상 초기화를 해줘야한다. \n",
    "W = tf.Variable(tf.random_normal([1]),name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
    "# 내가 찾고자 하는 선, 그래프\n",
    "hypothesis = X * W + b\n",
    "# operation -  tensor\n",
    "cost  = tf.reduce_mean(tf.square(hypothesis-Y))\n",
    "learning_rate = 0.01\n",
    "gradient = tf.reduce_mean((W*X-Y)*X)\n",
    "descent = W-learning_rate * gradient\n",
    "# assign은 텐서플로우가 그래프의 노드 개념이기 떄문에 업데이트하기 위해서는 assign이 필요하다. \n",
    "update = W.assign(descent)\n",
    "# 그래프가 다 연결되어 있어 가장 밑에것을 실행하면 된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 502.9448\n",
      "Cost: 1.2792095\n",
      "Cost: 0.92702216\n",
      "Cost: 0.92434996\n",
      "Cost: 0.92434996\n",
      "Cost: 0.92434996\n",
      "Cost: 0.92434996\n",
      "Cost: 0.92434996\n",
      "Cost: 0.92434996\n",
      "Cost: 0.92434996\n",
      "Cost: 0.92434996\n",
      "Cost: 0.92434996\n",
      "Cost: 0.92434996\n",
      "Cost: 0.92434996\n",
      "Cost: 0.92434996\n",
      "Cost: 0.92434996\n",
      "Cost: 0.92434996\n",
      "Cost: 0.92434996\n",
      "Cost: 0.92434996\n",
      "Cost: 0.92434996\n"
     ]
    }
   ],
   "source": [
    "sess= tf.Session()\n",
    "# 그래프의 variable 초기화한다\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(2000):\n",
    "    c,  _ = sess.run([cost,update], feed_dict = {X:[1,2,3],Y:[9,18,27]})\n",
    "    if step % 100 == 0:\n",
    "        print(\"Cost:\", c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
