{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape 맨끝에거 빼고 큰 덩어리부터 세면 된다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 * 4\n",
    "x_data = [[10., 12., 15., 16.], \n",
    "           [13., 22., 15., 17. ],\n",
    "           [82., 14., 19., 12. ],\n",
    "           [85, 12., 12., 12. ],\n",
    "           [85., 14., 15., 13. ]]\n",
    "# 5 * 1\n",
    "y_data = [[123],[345],[234.],[456.],[789]]\n",
    "\n",
    "# 위의 데이터를 받을 그릇\n",
    "X = tf.placeholder(tf.float32,shape = [None,4]) # shape이 shape의 두번째 차원이 4개를 받는다.\n",
    "Y = tf.placeholder(tf.float32,shape = [None,1]) # shape이 shape의 두번째 차원의 1이다.\n",
    "\n",
    "\n",
    "# weight를 담을 그릇(variable)\n",
    "W = tf.Variable(tf.random_normal([4,1]),name = \"weight\")\n",
    "# b의 shape은 뒤에 있는 숫자를 넣어주면 되기 때문에 1차원이고, 뒤에 갯수를 맞춰주면 된다.\n",
    "b = tf.Variable(tf.random_normal([1],name = 'bias'))\n",
    "# 초기화\n",
    "# hypothesis = x1 * w1 + x2 * w2 + x3 * w3 + b 가 아래와 같다.\n",
    "hypothesis = tf.matmul(X,W) + b\n",
    "# 기준(어떤 기준으로 학습할 것인지)\n",
    "cost = tf.reduce_mean(tf.square(hypothesis-Y))\n",
    "# 방식(어떠한 방식으로 기준을 실행 것인가)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 1e-4)\n",
    "# train이라는 grape 노드를 만들어라 train만 실행하면 아래서 위로 찾아들어간다. 거기 붙어있는 노드를 알아서 찾아서 실행한다.\n",
    "# 데이터가 필요한 게 있으면 타입마다 실행이 다그레 된다. \n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 139903.55 [[ 37.498978]\n",
      " [ 48.00377 ]\n",
      " [103.76326 ]\n",
      " [105.19908 ]\n",
      " [107.840965]]\n",
      "100 30464.006 [[189.39967]\n",
      " [275.02853]\n",
      " [485.91495]\n",
      " [494.80563]\n",
      " [509.62912]]\n",
      "200 28274.516 [[177.40808]\n",
      " [288.40335]\n",
      " [472.11835]\n",
      " [504.0474 ]\n",
      " [512.95605]]\n",
      "300 26518.293 [[166.3565 ]\n",
      " [299.1684 ]\n",
      " [459.62457]\n",
      " [512.69135]\n",
      " [516.07   ]]\n",
      "400 25103.312 [[156.8258 ]\n",
      " [308.53876]\n",
      " [448.26508]\n",
      " [520.573  ]\n",
      " [518.88196]]\n",
      "500 23957.996 [[148.63062]\n",
      " [316.69446]\n",
      " [437.92175]\n",
      " [527.7683 ]\n",
      " [521.4237 ]]\n",
      "600 23026.379 [[141.60172]\n",
      " [323.7854 ]\n",
      " [428.48993]\n",
      " [534.3466 ]\n",
      " [523.7241 ]]\n",
      "700 22264.607 [[135.59058]\n",
      " [329.94336]\n",
      " [419.8766 ]\n",
      " [540.3697 ]\n",
      " [525.8091 ]]\n",
      "800 21638.297 [[130.46675]\n",
      " [335.28406]\n",
      " [411.9992 ]\n",
      " [545.8927 ]\n",
      " [527.7015 ]]\n",
      "900 21120.398 [[126.115814]\n",
      " [339.909   ]\n",
      " [404.78406 ]\n",
      " [550.9644  ]\n",
      " [529.42163 ]]\n",
      "1000 20689.678 [[122.43765]\n",
      " [343.9077 ]\n",
      " [398.1658 ]\n",
      " [555.6286 ]\n",
      " [530.9872 ]]\n",
      "1100 20329.322 [[119.344246]\n",
      " [347.35873 ]\n",
      " [392.08624 ]\n",
      " [559.9242  ]\n",
      " [532.41437 ]]\n",
      "1200 20026.04 [[116.75859]\n",
      " [350.33072]\n",
      " [386.49316]\n",
      " [563.88586]\n",
      " [533.7172 ]]\n",
      "1300 19769.287 [[114.61316]\n",
      " [352.88434]\n",
      " [381.34045]\n",
      " [567.5448 ]\n",
      " [534.9085 ]]\n",
      "1400 19550.678 [[112.84895]\n",
      " [355.07257]\n",
      " [376.58655]\n",
      " [570.9288 ]\n",
      " [535.9993 ]]\n",
      "1500 19363.521 [[111.41424]\n",
      " [356.94232]\n",
      " [372.1946 ]\n",
      " [574.06256]\n",
      " [536.9995 ]]\n",
      "1600 19202.406 [[110.2638 ]\n",
      " [358.53424]\n",
      " [368.13116]\n",
      " [576.9684 ]\n",
      " [537.9181 ]]\n",
      "1700 19063.05 [[109.35827]\n",
      " [359.88434]\n",
      " [364.367  ]\n",
      " [579.6665 ]\n",
      " [538.7628 ]]\n",
      "1800 18941.928 [[108.66266]\n",
      " [361.02377]\n",
      " [360.87543]\n",
      " [582.175  ]\n",
      " [539.54095]]\n",
      "1900 18836.168 [[108.147224]\n",
      " [361.9804  ]\n",
      " [357.6322  ]\n",
      " [584.5095  ]\n",
      " [540.2586  ]]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(2000):\n",
    "    cost_val, hy_val, _ = sess.run([cost, hypothesis, train], feed_dict= {X:x_data, Y:y_data})\n",
    "    if step % 100 == 0:\n",
    "        print(step, cost_val, hy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
